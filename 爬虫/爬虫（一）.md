从我接触python爬虫开始，断断续续的学习到现在将将入门，已经过去了一个多月了，发现爬虫真的是一项浩瀚的工程，涉及的知识面非常广。我在这里主要是分享一下自己学的东西，同时做个总结。有写错或理解有误的地方欢迎各位大神指正。

什么是爬虫
用通俗易懂的语言来说就是个人写一个程序来模拟浏览器，发送网络请求，获取响应，然后我们把拿到的数据进行处理的一种行为。
> http://www.google.com/googlebooks/chrome/big_00.html
这个是谷歌一名工程师用漫画的形式写的浏览器原理（请自备梯子）。

爬虫的应用
你可以爬去想要的图片，爬取自己想看的视频等等你想要爬取的数据，只要你能通过浏览器访问的数据都可以通过爬虫获取，这里要有一个信念：只要是网络上有的就一定能爬，没有爬不到的内容只有想不到的内容。爬虫往小的做，可以爬一些简单的文件，如爬豆瓣电影，往大的做，诸如百度搜索，谷歌搜索。

爬虫到底是什么
就像浏览器一样，我们通过浏览器打开网页，获取网页中我们想要的那部分数据。

浏览器打开网页的过程：
当你在浏览器中输入地址后，经过DNS服务器（域名系统服务器，用于解析请求网站的IP地址）找到服务器主机，向服务器发送一个请求，服务器返回一个响应给浏览器结果，包括html,js,css等文件内容，浏览器解析出来最后呈现给用户在浏览器上看到的结果，即网站页面。页面由html（超文本标记语言）构成，爬虫就是为了获取这些内容，通过一定的方式分析和过滤html代码，从中获取我们想要资源（文本，图片，视频.....）

浏览器的请求

咱们先说说url，中文名统一资源定位符，用来定位网络上各种资源的位置和获得这些资源的方法。
url的组成：

url = 请求协议 + 域名 + 资源路径 + 参数

请求协议：是指用什么样的方法来获得这些资源，最常用的即http协议和https协议，其次为ftp协议。

域名：服务器地址。

资源路径：在服务器的哪个位置，就和你在硬盘上存储一个文件，在c盘360文件夹的那哪个位置。可有可无。

参数：如果文件是分段存储，指的是可能的文件片段存储位置。或为客户端传入服务器的一些参数，可有可无。

在浏览器页面，右击鼠标选择检查，出现一个窗口。如图：
005IjJa7zy7mB7Fim9mfc 690

下部为打开的调试工具，element就是页面的元素，可以看作是页面的html，我们就是从这里提取一些数据的，比如可以用xpath-helper来查看这些数据，在python中也有xpath方法。

005IjJa7zy7mB7kZtEJ09 690

Network是表示当前网络传输的一些内容，可以实时看到浏览器与服务器的交互内容。上面这个图打开的就是浏览器发送请求并获得响应的一个展示，Headers包括了请求头，响应头，传输文件等，是http或https协议的一部分。

response其实就是浏览器获得的响应，基本上与elements相同。
